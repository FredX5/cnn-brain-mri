{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":377107,"sourceType":"datasetVersion","datasetId":165566}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/faridjamalov/https-www-kaggle-com-code-faridjamalov-cnn-br?scriptVersionId=263833300\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\n# ------------------------------\n# Step 0: Suppress unnecessary TF warnings\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Hides INFO and WARNING logs\n# ------------------------------\n\n# ------------------------------\n# Step 1: Inspect Kaggle input directory\ndata_dir = \"/kaggle/input/brain-mri-images-for-brain-tumor-detection/brain_tumor_dataset\"\n\nprint(\"Classes:\", os.listdir(data_dir))\nfor folder in os.listdir(data_dir):\n    folder_path = os.path.join(data_dir, folder)\n    if os.path.isdir(folder_path):\n        print(folder, \":\", len(os.listdir(folder_path)))\n# ------------------------------\n\n# ------------------------------\n# Step 2: Check GPU availability\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        # Enable memory growth to avoid pre-allocating full GPU memory\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(f\"GPU(s) detected: {gpus}\")\n    except RuntimeError as e:\n        print(e)\nelse:\n    print(\"No GPU detected. Using CPU.\")\n\n# Optional: confirm TensorFlow version and available devices\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"Available devices:\", tf.config.list_physical_devices())\n# ------------------------------\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T15:05:03.532966Z","iopub.execute_input":"2025-09-23T15:05:03.533229Z","iopub.status.idle":"2025-09-23T15:05:04.418851Z","shell.execute_reply.started":"2025-09-23T15:05:03.53321Z","shell.execute_reply":"2025-09-23T15:05:04.418248Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"What this code does\nSuppress unnecessary warnings\n\nPrevents TensorFlow from printing lots of INFO and WARNING messages so the output is cleaner.\n\nInspect the dataset\n\nLooks into the Kaggle input folder.\n\nIdentifies the classes (e.g., tumor vs. no tumor) by checking folder names.\n\nCounts how many images are available in each class to understand dataset balance.\n\nCheck GPU availability\n\nDetermines whether a GPU is available for faster training.\n\nSets GPU memory to grow dynamically instead of reserving all memory upfront.\n\nFalls back to CPU if no GPU is found.\n\nConfirm TensorFlow version\n\nHelps ensure your code runs with the correct library version and is compatible with the system setup.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T15:05:04.419971Z","iopub.execute_input":"2025-09-23T15:05:04.420153Z","iopub.status.idle":"2025-09-23T15:05:04.423614Z","shell.execute_reply.started":"2025-09-23T15:05:04.420139Z","shell.execute_reply":"2025-09-23T15:05:04.423019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# ImageDataGenerator with augmentation and normalization\ndatagen = ImageDataGenerator(\n    rescale=1./255,           # Normalize pixel values\n    shear_range=0.2,          # Random shear\n    zoom_range=0.2,           # Random zoom\n    horizontal_flip=True,     # Random horizontal flip\n    validation_split=0.2      # 20% for validation\n)\n\n# Training generator\ntrain_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(150, 150),   # Resize images\n    batch_size=32,\n    class_mode='binary',      # Binary classification\n    subset='training',\n    shuffle=True\n)\n\n# Validation generator\nvalidation_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary',\n    subset='validation',\n    shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T15:05:04.424292Z","iopub.execute_input":"2025-09-23T15:05:04.424661Z","iopub.status.idle":"2025-09-23T15:05:04.742288Z","shell.execute_reply.started":"2025-09-23T15:05:04.424644Z","shell.execute_reply":"2025-09-23T15:05:04.741643Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Summary of what this does:\n\nNormalizes images to the 0–1 range.\n\nApplies data augmentation (shear, zoom, horizontal flip) to make the model more robust.\n\nSplits the dataset into training (80%) and validation (20%).\n\nPrepares iterators (generators) that feed images to the model in batches during training.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\nimport seaborn as sns\nimport cv2\n\n# -----------------------------\n# 1️⃣ Data Generators (senin kodundan)\ndata_dir = \"/kaggle/input/brain-mri-images-for-brain-tumor-detection/brain_tumor_dataset\"\n\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary',\n    subset='training',\n    shuffle=True\n)\n\nvalidation_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary',\n    subset='validation',\n    shuffle=False\n)\n\n# -----------------------------\n# 2️⃣ CNN Model\nmodel = Sequential([\n    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n    MaxPooling2D(2,2),\n    \n    Conv2D(64, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n    \n    Conv2D(128, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n    \n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')  # Binary classification\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\n# -----------------------------\n# 3️⃣ Train the model\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=15\n)\n\n# -----------------------------\n# 4️⃣ Plot Accuracy & Loss\nplt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label='Train Acc')\nplt.plot(history.history['val_accuracy'], label='Val Acc')\nplt.legend()\nplt.title('Accuracy')\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.legend()\nplt.title('Loss')\nplt.show()\n\n# -----------------------------\n# 5️⃣ Confusion Matrix & Classification Report\nval_steps = validation_generator.samples // validation_generator.batch_size + 1\npreds = model.predict(validation_generator, steps=val_steps)\ny_pred = (preds > 0.5).astype(int).ravel()\ny_true = validation_generator.classes\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=validation_generator.class_indices, yticklabels=validation_generator.class_indices)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n\nprint(classification_report(y_true, y_pred, target_names=validation_generator.class_indices.keys()))\n\n# -----------------------------\n# 6️⃣ Grad-CAM Example (1 test image)\ndef get_gradcam(model, img_array, layer_name='conv2d_2'):\n    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        loss = predictions[:,0]\n\n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\n# Load a test image from validation set\nimg_path = validation_generator.filepaths[0]\nimg = tf.keras.utils.load_img(img_path, target_size=(150,150))\nimg_array = tf.keras.utils.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0) / 255.0\n\nheatmap = get_gradcam(model, img_array)\n\nplt.imshow(img)\nplt.imshow(heatmap, cmap='jet', alpha=0.5)  # Overlay heatmap\nplt.title(\"Grad-CAM\")\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T15:05:04.742987Z","iopub.execute_input":"2025-09-23T15:05:04.743192Z","iopub.status.idle":"2025-09-23T15:05:43.997271Z","shell.execute_reply.started":"2025-09-23T15:05:04.743177Z","shell.execute_reply":"2025-09-23T15:05:43.996014Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This part of the code is preparing the dataset for model training and validation. It normalizes image pixel values and applies data augmentation (shear, zoom, horizontal flip) to improve model generalization. The ImageDataGenerator creates iterators (generators) that automatically load images in batches, resize them to a consistent shape, and split the data into training (80%) and validation (20%), making the workflow efficient for feeding images into a CNN model.","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='Train Acc')\nplt.plot(history.history['val_accuracy'], label='Val Acc')\nplt.legend(); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T15:05:43.998103Z","iopub.status.idle":"2025-09-23T15:05:43.998423Z","shell.execute_reply.started":"2025-09-23T15:05:43.998275Z","shell.execute_reply":"2025-09-23T15:05:43.998289Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\ny_pred = (model.predict(validation_generator) > 0.5).astype(int).ravel()\ny_true = validation_generator.classes\n\ncm = confusion_matrix(y_true, y_pred)\nsns.heatmap(cm, annot=True, fmt='d')\nprint(classification_report(y_true, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T15:05:43.999406Z","iopub.status.idle":"2025-09-23T15:05:43.999666Z","shell.execute_reply.started":"2025-09-23T15:05:43.999555Z","shell.execute_reply":"2025-09-23T15:05:43.999568Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This code is evaluating the performance of a trained model on the validation dataset.\n\nmodel.predict(validation_generator) generates predicted probabilities for each image.\n\n(> 0.5).astype(int) converts probabilities to binary class labels.\n\nconfusion_matrix shows the counts of true positives, true negatives, false positives, and false negatives, helping visualize where the model makes mistakes.\n\nsns.heatmap plots the confusion matrix for easy interpretation.\n\nclassification_report provides detailed metrics like precision, recall, F1-score, and accuracy for each class.\n Usability:\nThis helps in assessing how well the model performs, identifying biases, and guiding further improvements in training or preprocessing.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_true, y_pred, target_names=validation_generator.class_indices.keys()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T21:14:30.678229Z","iopub.execute_input":"2025-09-24T21:14:30.678507Z","iopub.status.idle":"2025-09-24T21:14:32.214179Z","shell.execute_reply.started":"2025-09-24T21:14:30.678477Z","shell.execute_reply":"2025-09-24T21:14:32.212861Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1671125265.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"],"ename":"NameError","evalue":"name 'y_true' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"img_path = validation_generator.filepaths[0]\n# Load image, preprocess, get heatmap, overlay\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T15:05:44.001802Z","iopub.status.idle":"2025-09-23T15:05:44.002001Z","shell.execute_reply.started":"2025-09-23T15:05:44.001904Z","shell.execute_reply":"2025-09-23T15:05:44.001913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport tensorflow as tf\n\n# -----------------------------\n# 1️⃣ Tahminleri al\nval_steps = validation_generator.samples // validation_generator.batch_size + 1\ny_pred_probs = model.predict(validation_generator, steps=val_steps)\ny_pred = (y_pred_probs > 0.5).astype(int).ravel()\ny_true = validation_generator.classes\n\n# -----------------------------\n# 2️⃣ Confusion Matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=validation_generator.class_indices, \n            yticklabels=validation_generator.class_indices)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()\n\n# -----------------------------\n# 3️⃣ Classification Report\nprint(\"Classification Report:\\n\")\nprint(classification_report(y_true, y_pred, target_names=validation_generator.class_indices.keys()))\n\n# -----------------------------\n# 4️⃣ Grad-CAM Fonksiyonu\ndef get_gradcam(model, img_array, layer_name='conv2d_2'):\n    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        loss = predictions[:,0]\n\n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\n# -----------------------------\n# 5️⃣ Örnek Grad-CAM Görselleştirme\nimg_path = validation_generator.filepaths[0]\nimg = tf.keras.utils.load_img(img_path, target_size=(150,150))\nimg_array = tf.keras.utils.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0) / 255.0\n\nheatmap = get_gradcam(model, img_array)\n\nplt.imshow(img)\nplt.imshow(heatmap, cmap='jet', alpha=0.5)  # Overlay heatmap\nplt.title(\"Grad-CAM\")\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T15:05:44.002763Z","iopub.status.idle":"2025-09-23T15:05:44.003062Z","shell.execute_reply.started":"2025-09-23T15:05:44.00292Z","shell.execute_reply":"2025-09-23T15:05:44.002937Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This code is focused on evaluating and interpreting the model’s predictions on the validation set:\n\nPredictions (y_pred)\n\nThe model predicts probabilities for each validation image.\n\nProbabilities are converted to binary class labels (0 or 1) for evaluation.\n\nConfusion Matrix\n\nVisualizes the model’s correct and incorrect predictions.\n\nsns.heatmap makes it easy to see true positives, true negatives, false positives, and false negatives.\n\nClassification Report\n\nProvides precision, recall, F1-score, and support for each class.\n\nHelps assess overall performance and class-specific performance.\n\nGrad-CAM Placeholder\n\nIndicates the next step would be to implement Grad-CAM, a technique to visualize which parts of an image the CNN focuses on when making predictions.\n\n Usability:\nThis section is essential for model evaluation and explainability, helping you identify strengths, weaknesses, and interpret how the CNN makes decisions.","metadata":{}},{"cell_type":"code","source":"# A simple Grad-CAM function adapted for Keras\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T15:05:44.004839Z","iopub.status.idle":"2025-09-23T15:05:44.005147Z","shell.execute_reply.started":"2025-09-23T15:05:44.004989Z","shell.execute_reply":"2025-09-23T15:05:44.005003Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"How it works:\n\nBuilds a gradient model that outputs both the last conv layer’s activations and the model’s predictions.\n\nComputes the gradient of the predicted class with respect to the last conv layer.\n\nAverages gradients across width and height to get importance weights for each feature map.\n\nComputes a weighted sum of feature maps to produce the class activation heatmap.\n\nNormalizes the heatmap between 0 and 1 for visualization.\n\n✅ Usability:\n\nAllows interpretation of CNN decisions by highlighting image regions influencing the prediction.\n\nUseful for debugging, explaining misclassifications, and improving trust in model predictions, especially in medical imaging tasks like brain tumor detection.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Create an ImageDataGenerator for data augmentation\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    shear_range=0.2,\n    zoom_range=0.2,\n    validation_split=0.2\n)\n\n# Load data from a directory\ntrain_generator = datagen.flow_from_directory(\n    'path/to/your/dataset/Training',\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator = datagen.flow_from_directory(\n    'path/to/your/dataset/Training',\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Load the test set separately without augmentation\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(\n    'path/to/your/dataset/Testing',\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T15:09:20.934627Z","iopub.execute_input":"2025-09-23T15:09:20.934873Z","iopub.status.idle":"2025-09-23T15:09:20.9542Z","shell.execute_reply.started":"2025-09-23T15:09:20.934856Z","shell.execute_reply":"2025-09-23T15:09:20.953128Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\n# Get true labels and predicted labels from the test generator\nY_pred = model.predict(test_generator)\ny_pred = np.argmax(Y_pred, axis=1)\ny_true = test_generator.classes\n\n# Print classification report\nprint('Classification Report')\ntarget_names = list(test_generator.class_indices.keys())\nprint(classification_report(y_true, y_pred, target_names=target_names))\n\n# Plot confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\nplt.title('Confusion Matrix')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T15:07:55.801611Z","iopub.execute_input":"2025-09-23T15:07:55.802218Z","iopub.status.idle":"2025-09-23T15:07:55.818145Z","shell.execute_reply.started":"2025-09-23T15:07:55.802194Z","shell.execute_reply":"2025-09-23T15:07:55.817328Z"}},"outputs":[],"execution_count":null}]}